From a84ed80d9a4a22f0084390e82597e9cf2c14465b Mon Sep 17 00:00:00 2001
From: Xiaoyao Li <xiaoyao.li@intel.com>
Date: Tue, 31 Aug 2021 15:34:50 +0800
Subject: [PATCH 0494/1418] KVM: MMU: TDX: split private large page if smaller
 level is desired

When page is AUG'ed as 2MB size but TD guest wants to accept with 4KB
size, it needs to split it into smaller size.

Signed-off-by: Xiaoyao Li <xiaoyao.li@intel.com>
---
 arch/x86/kvm/mmu/mmu.c | 25 ++++++++++++++++++++++---
 1 file changed, 22 insertions(+), 3 deletions(-)

diff --git a/arch/x86/kvm/mmu/mmu.c b/arch/x86/kvm/mmu/mmu.c
index 9b272f1c8dd8..81984bc35a4b 100644
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@ -1406,12 +1406,23 @@ static void drop_spte(struct kvm *kvm, u64 *sptep)
 		rmap_remove(kvm, sptep, old_spte);
 }
 
+static bool kvm_mmu_zap_private_spte(struct kvm *kvm, u64 *sptep);
+static void split_private_spte(struct kvm_vcpu *vcpu, u64 *sptep, u64 old_spte);
 
-static bool __drop_large_spte(struct kvm *kvm, u64 *sptep)
+static bool __drop_large_spte(struct kvm_vcpu *vcpu, u64 *sptep)
 {
+	u64 old_spte;
+
 	if (is_large_pte(*sptep)) {
 		WARN_ON(sptep_to_sp(sptep)->role.level == PG_LEVEL_4K);
-		drop_spte(kvm, sptep);
+
+		if (is_private_spte(vcpu->kvm, sptep)) {
+			old_spte = *sptep;
+			kvm_mmu_zap_private_spte(vcpu->kvm, sptep);
+			split_private_spte(vcpu, sptep, old_spte);
+		} else {
+			drop_spte(vcpu->kvm, sptep);
+		}
 		return true;
 	}
 
@@ -1420,7 +1431,7 @@ static bool __drop_large_spte(struct kvm *kvm, u64 *sptep)
 
 static void drop_large_spte(struct kvm_vcpu *vcpu, u64 *sptep)
 {
-	if (__drop_large_spte(vcpu->kvm, sptep)) {
+	if (__drop_large_spte(vcpu, sptep)) {
 		struct kvm_mmu_page *sp = sptep_to_sp(sptep);
 
 		kvm_flush_remote_tlbs_with_address(vcpu->kvm, sp->gfn,
@@ -3601,6 +3612,14 @@ static int __direct_map(struct kvm_vcpu *vcpu, gpa_t gpa, u32 error_code,
 			kvm_mmu_link_private_sp(vcpu, sp);
 	}
 
+	/*
+	 * For private page, if spte is already present. It must be one large
+	 * page split into smaller page. In this case, split_private_spte() in
+	 * drop_large_spte() already set up the private spte and AUG'ED page.
+	 */
+	if (is_private && is_shadow_present_pte(*it.sptep))
+		return  RET_PF_FIXED;
+
 	is_zapped_pte = is_zapped_private_pte(*it.sptep);
 
 	ret = mmu_set_spte(vcpu, it.sptep, pte_access,
-- 
2.31.1

