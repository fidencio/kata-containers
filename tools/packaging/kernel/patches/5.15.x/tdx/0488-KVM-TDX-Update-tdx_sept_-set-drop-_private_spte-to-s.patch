From 387284729c41802add87953035ea18ef8b6e132f Mon Sep 17 00:00:00 2001
From: Xiaoyao Li <xiaoyao.li@intel.com>
Date: Tue, 31 Aug 2021 15:34:44 +0800
Subject: [PATCH 0488/1418] KVM: TDX: Update tdx_sept_{set,drop}_private_spte()
 to support 2MB level

Allow 2MB page level AUG and REMOVE for TDX pages.

Signed-off-by: Xiaoyao Li <xiaoyao.li@intel.com>
---
 arch/x86/kvm/vmx/tdx.c | 27 +++++++++++++++++----------
 1 file changed, 17 insertions(+), 10 deletions(-)

diff --git a/arch/x86/kvm/vmx/tdx.c b/arch/x86/kvm/vmx/tdx.c
index b5f8267cc86e..4a03857843cd 100644
--- a/arch/x86/kvm/vmx/tdx.c
+++ b/arch/x86/kvm/vmx/tdx.c
@@ -1493,16 +1493,18 @@ static void tdx_sept_set_private_spte(struct kvm_vcpu *vcpu, gfn_t gfn,
 	struct tdx_ex_ret ex_ret;
 	hpa_t source_pa;
 	u64 err;
+	int i;
 
 	if (WARN_ON_ONCE(is_error_noslot_pfn(pfn) || kvm_is_reserved_pfn(pfn)))
 		return;
 
-	/* TODO: handle large pages. */
-	if (KVM_BUG_ON(level != PG_LEVEL_4K, vcpu->kvm))
+	/* Only support 4KB and 2MB pages */
+	if (KVM_BUG_ON(level > PG_LEVEL_2M, vcpu->kvm))
 		return;
 
 	/* Pin the page, KVM doesn't yet support page migration. */
-	get_page(pfn_to_page(pfn));
+	for (i = 0; i < KVM_PAGES_PER_HPAGE(level); i++)
+		get_page(pfn_to_page(pfn + i));
 
 	/* Build-time faults are induced and handled via TDH_MEM_PAGE_ADD. */
 	if (is_td_finalized(kvm_tdx)) {
@@ -1537,9 +1539,10 @@ static void tdx_sept_drop_private_spte(struct kvm *kvm, gfn_t gfn, enum pg_level
 	hpa_t hpa_with_hkid;
 	struct tdx_ex_ret ex_ret;
 	u64 err;
+	int i;
 
-	/* TODO: handle large pages. */
-	if (KVM_BUG_ON(level != PG_LEVEL_4K, kvm))
+	/* Only support 4KB and 2MB pages */
+	if (KVM_BUG_ON(level > PG_LEVEL_2M, kvm))
 		return;
 
 	if (is_hkid_assigned(kvm_tdx)) {
@@ -1549,15 +1552,19 @@ static void tdx_sept_drop_private_spte(struct kvm *kvm, gfn_t gfn, enum pg_level
 		if (SEPT_ERR(err, &ex_ret, TDH_MEM_PAGE_REMOVE, kvm))
 			return;
 
-		hpa_with_hkid = set_hkid_to_hpa(hpa, (u16)kvm_tdx->hkid);
-		err = tdh_phymem_page_wbinvd(hpa_with_hkid);
-		if (TDX_ERR(err, TDH_PHYMEM_PAGE_WBINVD, NULL))
-			return;
+		for (i = 0; i < KVM_PAGES_PER_HPAGE(level); i++) {
+			hpa_with_hkid = set_hkid_to_hpa(hpa, (u16)kvm_tdx->hkid);
+			err = tdh_phymem_page_wbinvd(hpa_with_hkid);
+			if (TDX_ERR(err, TDH_PHYMEM_PAGE_WBINVD, NULL))
+				return;
+			hpa += PAGE_SIZE;
+		}
 	} else if (tdx_reclaim_page((unsigned long)__va(hpa), hpa, level)) {
 		return;
 	}
 
-	put_page(pfn_to_page(pfn));
+	for (i = 0; i < KVM_PAGES_PER_HPAGE(level); i++)
+		put_page(pfn_to_page(pfn + i));
 }
 
 static int tdx_sept_link_private_sp(struct kvm_vcpu *vcpu, gfn_t gfn,
-- 
2.31.1

