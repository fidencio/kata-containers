From f66b18914df0efbab623578f21ed79ecfb8d954b Mon Sep 17 00:00:00 2001
From: Yuan Yao <yuan.yao@intel.com>
Date: Thu, 1 Jul 2021 16:22:29 +0800
Subject: [PATCH 0467/1418] KVM: TDX: Update guest register context for debug
 enabled TD guest

A TD guest with debug enabled may need update its register context
if instruction emulation/skip was done by KVM. e.g GPRs update to
reflect the effect of emulated instruction or RIP update to skip
the emulated instruction, or both.

This is 2/2 preparation for instruction emulation/skip for TD
guest, the later patch will introduce DR accessing vmexit which
rely on this one.

Signed-off-by: Yuan Yao <yuan.yao@intel.com>
---
 arch/x86/kvm/vmx/tdx.c | 43 ++++++++++++++++++++++++++++++++++++++----
 1 file changed, 39 insertions(+), 4 deletions(-)

diff --git a/arch/x86/kvm/vmx/tdx.c b/arch/x86/kvm/vmx/tdx.c
index 745119dea60d..4db9e030c8ea 100644
--- a/arch/x86/kvm/vmx/tdx.c
+++ b/arch/x86/kvm/vmx/tdx.c
@@ -660,6 +660,7 @@ static void tdx_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 
 	vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
 	vcpu->arch.cr0_guest_owned_bits = -1ul;
+	vcpu->arch.regs_dirty = 0;
 
 	return;
 
@@ -741,6 +742,7 @@ static void tdx_switch_perf_msrs(struct kvm_vcpu *vcpu)
 }
 
 u64 __tdx_vcpu_run(hpa_t tdvpr, void *regs, u32 regs_mask);
+static void tdx_flush_gprs_dirty(struct kvm_vcpu *vcpu, bool force);
 
 static noinstr void tdx_vcpu_enter_exit(struct kvm_vcpu *vcpu,
 					struct vcpu_tdx *tdx)
@@ -776,6 +778,14 @@ static fastpath_t tdx_vcpu_run(struct kvm_vcpu *vcpu)
 	else if (td_profile_allowed(kvm_tdx))
 		tdx_switch_perf_msrs(vcpu);
 
+	/*
+	 * limited to debug td only due to now only debug
+	 * td guest need this feature for instructioin
+	 * emulation/skipping.
+	 */
+	if (is_debug_td(vcpu))
+		tdx_flush_gprs_dirty(vcpu, false);
+
 	tdx_vcpu_enter_exit(vcpu, tdx);
 
 	tdx_user_return_update_cache();
@@ -2210,23 +2220,48 @@ static void tdx_cache_gprs(struct kvm_vcpu *vcpu)
 		return;
 
 	for (i = 0; i < NR_VCPU_REGS; i++) {
-		if (i == VCPU_REGS_RSP || i == VCPU_REGS_RIP)
+
+		if (i == VCPU_REGS_RIP) {
+			vcpu->arch.regs[i] = td_vmcs_read64(tdx, GUEST_RIP);
 			continue;
+		}
+		if (i == VCPU_REGS_RSP) {
+			vcpu->arch.regs[i] = td_vmcs_read64(tdx, GUEST_RSP);
+			continue;
+		}
 
 		vcpu->arch.regs[i] = td_gpr_read64(tdx, i);
 	}
 }
 
-static void tdx_flush_gprs(struct kvm_vcpu *vcpu)
+static void tdx_flush_gprs_dirty(struct kvm_vcpu *vcpu, bool force)
 {
 	struct vcpu_tdx *tdx = to_tdx(vcpu);
 	int i;
 
+	for (i = 0; i < NR_VCPU_REGS; i++) {
+		if (!kvm_register_is_dirty(vcpu, i) && !force)
+			continue;
+
+		if (i == VCPU_REGS_RSP) {
+			td_vmcs_write64(tdx, GUEST_RSP, vcpu->arch.regs[i]);
+			continue;
+		}
+		if (i == VCPU_REGS_RIP) {
+			td_vmcs_write64(tdx, GUEST_RIP, vcpu->arch.regs[i]);
+			continue;
+		}
+
+		td_gpr_write64(tdx, i, vcpu->arch.regs[i]);
+	}
+}
+
+static void tdx_flush_gprs(struct kvm_vcpu *vcpu)
+{
 	if (!is_td_vcpu(vcpu) || KVM_BUG_ON(!is_debug_td(vcpu), vcpu->kvm))
 		return;
 
-	for (i = 0; i < NR_VCPU_REGS; i++)
-		td_gpr_write64(tdx, i, vcpu->arch.regs[i]);
+	tdx_flush_gprs_dirty(vcpu, true);
 }
 
 static int tdx_prepare_memory_region(struct kvm *kvm,
-- 
2.31.1

